<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0"
     xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Kirk Kittell</title>
    <link>https://www.kirkkittell.com/</link>
    <description>kirkkittell.com</description>
    <language>en-us</language>
    <lastBuildDate>Fri, 20 Feb 2026 07:06:00 CST</lastBuildDate>

    <item>
      <title>The Captain's Newsletter: 2026-003</title>
      <link>https://www.kirkkittell.com/story/2026-02-11.html#2026-02-11_01</link>
      <guid>https://www.kirkkittell.com/story/2026-02-11.html#2026-02-11_01</guid>
      <pubDate>Wed, 11 Jan 2026 08:00:00 CST</pubDate>
      <content:encoded><![CDATA[

      ]]></content:encoded>
    </item>

    <item>
      <title>A quick script to pull links from Instapaper</title>
      <link>https://www.kirkkittell.com/story/2026-02-06.html#2026-02-06_01</link>
      <guid>https://www.kirkkittell.com/story/2026-02-06.html#2026-02-06_01</guid>
      <pubDate>Fri, 06 Feb 2026 21:37:00 CST</pubDate>
      <content:encoded><![CDATA[
      <p>Moving on from <a href="2026-01-29.html">pulling links from Tumblr</a>, where I fling links for any articles I read...</p>

      <p>I also put links of articles to read later in <a href="https://www.instapaper.com">Instapaper</a>. Somewhere I've got a post about how I use Instapaper, but I haven't excavated and reposted it yet. In short: Instapaper is nice because you can post a link to an article that you think you want to read now, but then not read it, and come back to it later and decide if you actually want to read it. Sounds silly, but gets around whatever impulse that is for reading junky super NOW articles about whatever's in the news&mdash;the sort of stuff that's often primed for Engagement moreso than Information.</p>

      <p>Instapaper is also nice because it feels like an old(-ish) school internet tool that is useful without being flashy or pushy or annoying. It does what it does, and does it well.</p>

      <p>In the back of my mind, I have this idea of building out a knowledge graph based on the things I read. I try to keep it in the back of my mind because I'd rather spend the time in the real world and not spend so much time making interesting but useless toys. Tumblr as a link blog and Instapaper as a place to capture article text and highlights are two aspects of that graph. Another would be the notes I have in OneNote. Another might be the feeds I subscribe to in Feedly (say, see which articles I've read, but have or have not subscribed to the RSS feed). Each artifact (which could be described by any number of the previously named things) might relate to another artifact as a citation or link or reference or author or whatever.</p>

      <p>Where do ideas come from? Where do they go? Just something that's been banging around in my head, especially at work where there is some messy progression of results begetting ideas begetting results, and so on and so on.</p>

      <p>Anyway. In the meanwhile, here's a quick <a href="attachments/2026-02-06/instapaper_2026-02-06.py">python script</a> that grabs articles from the "archived" folder in Instapaper.</p>
      
      <code>
        <p>import json
        <br />from pathlib import Path
        <br />from requests_oauthlib import OAuth1Session
        </p>

        <p>def load_keys():
        <br />&nbsp;&nbsp;&nbsp;&nbsp;# Retrieve API keys from a separate location from code
        </p>

        <p>&nbsp;&nbsp;&nbsp;&nbsp;# Cross-platform home directory
        <br />&nbsp;&nbsp;&nbsp;&nbsp;home = Path.home()
        </p>

        <p>&nbsp;&nbsp;&nbsp;&nbsp;# Shared subpath on both Mac and PC
        <br />&nbsp;&nbsp;&nbsp;&nbsp;keyfile = home / 'OneDrive' / 'Programs' / 'instapaper' / 'instapaper_api_keys.json'
        </p>

        <p>&nbsp;&nbsp;&nbsp;&nbsp;with open(keyfile, 'r') as f:
        <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return json.load(f)
        </p>

        <p>def get_oauth_token(keys):
        <br />&nbsp;&nbsp;&nbsp;&nbsp;# Step 1: Get an OAuth access token via xAuth
        <br />&nbsp;&nbsp;&nbsp;&nbsp;oauth = OAuth1Session(keys['consumer_id'], client_secret=keys['consumer_secret'])
        </p>

        <p>&nbsp;&nbsp;&nbsp;&nbsp;response = oauth.post(
        <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'https://www.instapaper.com/api/1/oauth/access_token',
        <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;data={
        <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'x_auth_username': keys['username'],
        <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'x_auth_password': keys['password'],
        <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'x_auth_mode': 'client_auth',
        <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
        <br />&nbsp;&nbsp;&nbsp;&nbsp;)
        </p>

        <p>&nbsp;&nbsp;&nbsp;&nbsp;if response.status_code != 200:
        <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;raise Exception('xAuth failed: ' + response.text)
        </p>

        <p>&nbsp;&nbsp;&nbsp;&nbsp;# Parse token + secret
        <br />&nbsp;&nbsp;&nbsp;&nbsp;token_data = dict(item.split('=') for item in response.text.split('&'))
        </p>

        <p>&nbsp;&nbsp;&nbsp;&nbsp;print('Authenticated!')
        <br />&nbsp;&nbsp;&nbsp;&nbsp;return token_data
        </p>

        <p>def get_auth(api_keys, oauth_token):
        <br />&nbsp;&nbsp;&nbsp;&nbsp;auth = OAuth1Session(
        <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;api_keys['consumer_id'],
        <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;client_secret=api_keys['consumer_secret'],
        <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;resource_owner_key=oauth_token['oauth_token'],
        <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;resource_owner_secret=oauth_token['oauth_token_secret']
        <br />&nbsp;&nbsp;&nbsp;&nbsp;)
        <br />&nbsp;&nbsp;&nbsp;&nbsp;return auth
        </p>

        <p>def fetch_bookmarks(api_keys, oauth_token, limit, folder_id=None):
        <br />&nbsp;&nbsp;&nbsp;&nbsp;auth = get_auth(api_keys, oauth_token)
        <br />&nbsp;&nbsp;&nbsp;&nbsp;resp = auth.post(
        <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'https://www.instapaper.com/api/1/bookmarks/list',
        <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;data={
        <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'folder_id': folder_id,
        <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'limit': limit
        <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}
        <br />&nbsp;&nbsp;&nbsp;&nbsp;)
        </p>

        <p>&nbsp;&nbsp;&nbsp;&nbsp;resp_json = resp.json()
        <br />&nbsp;&nbsp;&nbsp;&nbsp;bookmarks = []
        <br />&nbsp;&nbsp;&nbsp;&nbsp;for item in resp_json:
        <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if item.get('type') == 'bookmark':
        <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bookmarks.append(item)
        </p>

        <p>&nbsp;&nbsp;&nbsp;&nbsp;return bookmarks
        </p>

        <p>if __name__ == '__main__':
        <br />&nbsp;&nbsp;&nbsp;&nbsp;api_keys = load_keys()
        <br />&nbsp;&nbsp;&nbsp;&nbsp;oauth_token = get_oauth_token(api_keys)
        <br />&nbsp;&nbsp;&nbsp;&nbsp;bookmarks = fetch_bookmarks(api_keys, oauth_token, limit=10, folder_id='archive')
        <br />&nbsp;&nbsp;&nbsp;&nbsp;for b in bookmarks:
        <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(f"{b['bookmark_id']}, {b['url']}, {b['title']}, {b['time']}")
      </code>

      <p>That returns something like:</p>

      <code>
        <p>1622499199, https://www.newyorker.com/magazine/2020/12/14/the-skeletons-at-the-lake, The Skeletons at the Lake, 1770208605
        <br />1967077764, https://www.nytimes.com/2026/01/25/business/mississippi-delta-farmers-rice-prices.html, Hard Times in the Delta as Farmers Consider Letting Crops Rot, 1769352919
        <br />1967026977, https://www.polygon.com/brian-graden-south-park-interview-matt-stone-trey-parker-donald-trump/, 29 years later, the Hollywood producer behind South Park weighs in on its anti-Trump season, 1769345761
        <br />1958813273, https://www.theatlantic.com/ideas/2025/12/death-college-football-bowl-playoff/685454/, The Slow, Inevitable Death of the Bowl Game, 1768142163
        <br />1950813592, https://fortune.com/2025/12/25/cursor-ceo-michael-truell-vibe-coding-warning-generative-ai-assistant/, Cursor CEO warns vibe coding builds 'shaky foundations' and eventually 'things start to crumble’ | Fortune, 1766773591
        <br />1941006954, https://www.theringer.com/2025/11/19/tv/tv-show-coaching-trees-ranking, Which TV Show Has the Best Coaching Tree?, 1765686843      
        <br />1860930300, https://english.elpais.com/culture/2025-07-20/the-bewildering-phenomenon-of-declining-quality.html, The bewildering phenomenon of declining quality, 1765190737
        <br />1939289925, https://www.salon.com/2001/09/24/cobain/, Kurt Cobain and a dream about pop - Salon.com, 1765170576
        <br />1630731970, https://slate.com/business/2023/08/sleeper-car-trains-trend-travel.html, The Bliss of Being There by Morning, 1764900144
        <br />1634972476, https://www.thecut.com/article/erykah-badu-profile.html, A Four-Hour Phone Call With Erykah Badu, 1764872740</p>
      </code>

      ]]></content:encoded>
    </item>

    <item>
      <title>Cerebellum</title>
      <link>https://www.kirkkittell.com/story/2026-02-03.html#2026-02-03_01</link>
      <guid>https://www.kirkkittell.com/story/2026-02-03.html#2026-02-03_01</guid>
      <pubDate>Tue, 03 Feb 2026 07:40:00 CST</pubDate>
      <content:encoded><![CDATA[
      <p>"<a href="https://radiolab.org/podcast/song-of-the-cerebellum">Song of the Cerebellum</a>". <em>Radiolab</em> (2026-01-30).</p>
      <p>This was a really good episode of <em>Radiolab</em>. I recommend listening to it.</p>
      <p>The cerebrum is bigger, flashier, the part of the brain that you actually think is the brain. The cerebellum is more interesting&mdash;to me, at least, although I never considered it before listening to this episode. Most of the work I've done in my career is systems-type work&mdash;how does this connect to that, and what are the effects? That seems to be what's happening in the brain. The cerebrum has the big capabilities, and the cerebellum is the systems orchestrator that helps it all work together, producing the whole effect from the parts.</p>

      ]]></content:encoded>
    </item>

    <item>
      <title>30 km in, 30 km out</title>
      <link>https://www.kirkkittell.com/story/2026-02-02.html#2026-02-02_01</link>
      <guid>https://www.kirkkittell.com/story/2026-02-02.html#2026-02-02_01</guid>
      <pubDate>Mon, 02 Feb 2026 08:00:00 CST</pubDate>
      <content:encoded><![CDATA[
      <p>Starting out the year: big plans, big crash. Lots of momentum, loss of momentum. It's the way of the resolutioneer.</p>
      <p>One thing ended up working well enough from calling out some direction on the <a href="2026-01-01.html">the first of the year</a>: running got back on track. 30 km the first full week (2026-W02), then some fall off in the middle, 20 km or so per week, then back to 30 km again last week (2026-W05). I can't believe I even have to concentrate on distances that small these days&mdash;over the course of a full week, no less&nbsp;but here we are. At the very least, I can look at the pickup at the end and take something from that.</p>
      <p>Now: +5 km per week for February. Get back to 50 km per week before summer, then decide where to go from there.</p>

      ]]></content:encoded>
    </item>

    <item>
      <title>A quick script to pull links from Tumblr</title>
      <link>https://www.kirkkittell.com/story/2026-01-29.html#2026-01-29_01</link>
      <guid>https://www.kirkkittell.com/story/2026-01-29.html#2026-01-29_01</guid>
      <pubDate>Thu, 29 Jan 2026 07:00:00 CST</pubDate>
      <content:encoded><![CDATA[
      <p>I use Tumblr as a linkblog: <a href="https://kittell.tumblr.com">kittell.tumblr.com</a>. Read an article or listen to a radio show (a "Pod Cast"), then throw the link to it up there&mdash;for what reason, I'm not sure. Probably just <a href="2026-01-09.html#2026-01-09_01">note hoarding</a>. What if the though slips away, etc.</p>
      <p>Anyway, they're there, and I'll scroll back through the list and grab a few article/show links for the <a href="newsletter">newsletter</a>. I've always wanted to make something that will go back and manage the links for me, plus the notes that about the article that I keep in Instapaper or OneNote (or Evernote, that's how long I've been thinking about it, I haven't used that service in years, thanks private equity). There's no need for that either, just a fun project to see how things work.</p>
      <p>So here's a quick something (<a href="attachments/2026-01-29/tumblr_2026-01-29.py">tumblr_2026-01-29.py</a>) that goes to Tumblr, finds links I've posted along with the post ID and timestamp, and brings them back. It doesn't do anything interesting with them. Step one is just getting them. It was all fairly straightforward if you look at the response except for the <a href="https://www.tumblr.com/docs/npf">Neue Post Format</a> info in the body, which is more JSON info packed into a string.</p>
      <code>
        <p>import requests
        <br />import json
        <br />import html
        <br />from pathlib import Path
        <br />from bs4 import BeautifulSoup</p>

        <br />BLOG_IDENTIFIER = "kittell.tumblr.com"
        <br />LIMIT = 10</p>

        <p>def load_tumblr_keys():
            <br />&nbsp;&nbsp;# Retrieve API keys from a separate location from code
            </p>
            
            <p>&nbsp;&nbsp;# Cross-platform home directory
            <br />&nbsp;&nbsp;home = Path.home()</p>

            <p>&nbsp;&nbsp;# Shared subpath on both Mac and PC
            <br />&nbsp;&nbsp;keyfile = home / "OneDrive" / "Programs" / "tumblr" / "tumblr_api_keys.json"</p>

            <p>&nbsp;&nbsp;with open(keyfile, "r") as f:
                <br />&nbsp;&nbsp;&nbsp;&nbsp;return json.load(f)</p>

        <p>def get_posts(keys):
            <br />&nbsp;&nbsp;url = f"https://api.tumblr.com/v2/blog/{BLOG_IDENTIFIER}/posts/link"
            <br />&nbsp;&nbsp;params = {
                <br />&nbsp;&nbsp;&nbsp;&nbsp;"api_key": keys['consumer_key'],
                <br />&nbsp;&nbsp;&nbsp;&nbsp;"limit": LIMIT
            <br />&nbsp;&nbsp;}</p>

            <p>&nbsp;&nbsp;response = requests.get(url, params=params)
            <br />&nbsp;&nbsp;data = response.json()
            <br />&nbsp;&nbsp;posts = data["response"]["posts"]</p>

            <p>&nbsp;&nbsp;return posts

        <p>def get_npfdata_from_body(body):
            <br />&nbsp;&nbsp;soup = BeautifulSoup(body, 'html.parser')</p>

            <p>&nbsp;&nbsp;# Step 1: extract the attribute
            <br />&nbsp;&nbsp;raw = soup.p["data-npf"]</p>

            <p>&nbsp;&nbsp;# Step 2: unescape HTML entities (&quot; → ")
            <br />&nbsp;&nbsp;unescaped = html.unescape(raw)</p>

            <p>&nbsp;&nbsp;# Step 3: parse JSON
            <br />&nbsp;&nbsp;npf_data = json.loads(unescaped)</p>

            <p>&nbsp;&nbsp;return npf_data</p>

        <p>if __name__ == "__main__":
            <br />&nbsp;&nbsp;keys = load_tumblr_keys()
            <br />&nbsp;&nbsp;posts = get_posts(keys)
            <br />&nbsp;&nbsp;for post in posts:
                <br />&nbsp;&nbsp;&nbsp;&nbsp;npf_data = get_npfdata_from_body(post['body'])
                <br />&nbsp;&nbsp;&nbsp;&nbsp;print(f'{post['id']}, {post['date']}, {npf_data['url']}')</p>

      </code>
      <p>From that, I get:</p>
      <code>
        <p>806946606212644864, 2026-01-28 01:37:33 GMT, https://www.stlpr.org/economy-business/2026-01-26/facing-insurmountable-challenges-alton-steel-will-close-doors
        <br />806809748378943488, 2026-01-26 13:22:15 GMT, https://sixsongs.blogspot.com/2008/12/winter-wonderland-snowin-on-raton.html
        <br />806809201947115520, 2026-01-26 13:13:34 GMT, https://www.npr.org/2012/01/02/144587802/winter-songs-van-zandts-snowin-on-raton
        <br />806735156158316544, 2026-01-25 17:36:38 GMT, https://www.nytimes.com/interactive/2026/01/23/weather/winter-storm-snow-maps.html
        <br />806581104350986240, 2026-01-24 00:48:03 GMT, https://timkreider.substack.com/p/the-least-merry-prankster?utm_source=substack&utm_medium=email
        <br />806411463256309762, 2026-01-22 03:51:40 GMT, https://www.agriculture.com/precision-planting-unveils-arrowtube-to-improve-corn-emergence-uniformity-11889368
        <br />806397347786588160, 2026-01-22 00:07:19 GMT, https://www.garbageday.email/p/am-i-too-stupid-to-vibe-code
        <br />806215875766157312, 2026-01-20 00:02:54 GMT, https://github.blog/ai-and-ml/generative-ai/what-ai-is-actually-good-for-according-to-developers/
        <br />806215594342072320, 2026-01-19 23:58:25 GMT, https://www.npr.org/2026/01/15/nx-s1-5611117/beat-anxiety-insomnia-get-back-to-sleep
        <br />806215385008537600, 2026-01-19 23:55:06 GMT, https://arstechnica.com/information-technology/2026/01/10-things-i-learned-from-burning-myself-out-with-ai-coding-agents/</p>
      </code>
      ]]></content:encoded>
    </item>

    <item>
      <title>The Captain's Newsletter 2026-002</title>
      <link>https://www.kirkkittell.com/story/2026-01-26.html#2026-01-26_01</link>
      <guid>https://www.kirkkittell.com/story/2026-01-26.html#2026-01-26_01</guid>
      <pubDate>Mon, 26 Jan 2026 08:00:00 CST</pubDate>
      <content:encoded><![CDATA[
      <p>The Captain's Newsletter 2026-002: <a href="/newsletter/newsletter_2026-001.html">Branches of barbed wire</a></p>
      ]]></content:encoded>
    </item>


    <item>
      <title>Shimmer</title>
      <link>https://www.kirkkittell.com/story/2026-01-24.html#2026-01-24_01</link>
      <guid>https://www.kirkkittell.com/story/2026-01-24.html#2026-01-24_01</guid>
      <pubDate>Sat, 24 Jan 2026 20:38:00 CST<</pubDate>
      <content:encoded><![CDATA[
      <p>Today I saw something I'd never seen before: heat shimmer in the cold. This morning, sometime after a weak sun had come up, it was about -15&deg;C. Or 14&deg;C. What's the difference, etc. We opened up the balcony door from the office room to look out on the street in front of the house, after it was cold but before it started snowing. Looking up the street, the air danced and waved, like looking through the air above a grill or a blacktop road on a hot summer day.</p>
      <p>I refer you back to the temperature. It was not a hot summer day.</p>
      <p>So what we were seeing, it took us a moment to realize, that the air coming out from the house&mdash;which we keep at a balmy 17&deg;C&mdash;was warm enough compared to the outside air to shimmer in front of us. We were seeing something we wouldn't expect to see, and the parts of our brains dedicated to filtering out any potential nonsense coming through our eyes simply said "Nah" for a few moments.</p>
      ]]></content:encoded>
    </item>

    <item>
      <title>Automation, take 10</title>
      <link>https://www.kirkkittell.com/story/2026-01-18.html#2026-01-18_01</link>
      <guid>https://www.kirkkittell.com/story/2026-01-18.html#2026-01-18_01</guid>
      <pubDate>Sun, 18 Jan 2026 20:14:00 CST</pubDate>
      <content:encoded><![CDATA[
      <p>Someday&mdash;someday!&mdash;I'll pull in the archives here. I'll spend useless hours copying and pasting from the old into this new. Somewhere out there, in The Old, is a few posts about automation. I'd like to point you there, Dear Reader, but I'd also like to read it myself just to see if I was going to write the same thing over again.</p>
      <p>No matter. For everything that getting older takes away, it also gives back in the freedom to not care or to forget or whatever it is and tell the same story again, yet again, an old skipping record (red flag reference for Old right there) stuck in the same radius from which it will never move beyond without intervention.</p>
      <p>None of that, per usual, is the point.</p>
      <p>The point was, I guess, what things I want The Robots to finally come and wrest from my cold, dumb hands and just <em>do</em> for me so I don't have to. Don't make me copypaste again. Do it for me, Mr. Robot.</p>
      <p>I don't work with or know many people who use some kind of large language model software product to do their work or... whatever the rest of it is when you're not at work. I know one guy at work who uses Copilot effectively to help him build software. My wife uses ChatGPT to design things around the house. (She'll never see this, so I have no reason to pose, but she is extremely effective at understanding some kind of specification for home design, say, what elements need to be incorporated into a room or porch, and then translating that specification into something the software tool can use to make recommendations and draw prospective images. I feel like that minimizes the activity, but it's something that engineers that I know could learn from.)</p>
      <p>I feel like I have about three use cases for AI software suggestion tools:</p>
      <ol>
        <li>Do the things I've done a thousand times, but don't remember the syntax for how to do off the top of my head. I think the most frequent example is something like when I'm using Python and want to open a file. I've done it a thousand times, and I always have to look it up. No more, my AI friend will do it for me.</li>
        <li>Do the things I have no idea how to do correctly, but I want to understand and I'll come back to later. The most pertinent example to me now is how to make some machine vision models for [things at work]. I'm interested in the topic. I'll put in the time to figure it out eventually. But I need something that works Good Enough today.</li>
        <li>Things that are Actively Disinteresting. I do not care how to connect to AWS. Or Google Cloud. Or setting up a session with a database. I'm glad that there are people who know how to do this, but I'm also glad that it isn't me. Just give me some code that works so I can do the parts I like.</li>
      </ol>
      <p>That's it, really. I use coding assist tools like a fastbreak in basketball, passing the ball forward to the tool, that passes it back to me, and so on, until someone lays it in the basket.</p>
      <p>Using the tools at home is useful, I know. I believe it. I don't need to be convinced. But I just hate the word Efficiency when it comes to home. Or Productivity. Let me leave that at work. Efficiency is cold, and home should be warm. I've used Copilot to find me recipes for chicken breasts that I had in the refrigerator, but I felt like that was an intrusion of sorts. (They were pretty good though, lemon and cumin leading the way.)</p>
      <p>Stream of consciousness nonsense. That's how it goes. I'm looking forward to when the hype dies down, and a tool can just be a tool, not a revolution, not the greatest thing since sliced bread. Sometimes&mdash;most of the time&mdash;I'm not looking for something that changes my life, I'm just looking for something that turns a screw or pounds a nail. I do worry about forgetting what it is, exactly, that screws and nails do, and why I want to use them, and what larger things can be built with them.</p>

      ]]></content:encoded>
    </item>

    <item>
      <title>Now reading: Small Is Beautiful</title>
      <link>https://www.kirkkittell.com/story/2026-01-17.html#2026-01-17_01</link>
      <guid>https://www.kirkkittell.com/story/2026-01-17.html#2026-01-17_01</guid>
      <pubDate>Sat, 17 Jan 2026 20:00:00 CST</pubDate>
      <content:encoded><![CDATA[
      <p>Now reading: <em>Small Is Beautiful: Economics as if People Mattered</em> by E.F. Schumacher. Activity on Goodreads: <a href="https://www.goodreads.com/review/show/2466711865">goodreads.com/review/show/2466711865</a>. Based on the date I added it to Goodreads, 22 July 2018, I'd say that I found this book in the citations list of <em><a href="https://www.goodreads.com/review/show/2391349283">Seeing Like a State</a></em> by James Scott. That's a good one, I recommend it. I must have encountered <em>Small Is Beautiful</em> again recently to have gone and requested it from the library, but I don't remember when or why.</p>
      <p>This is my number two use case for Goodreads: finding out when I added a book to my <a href="https://www.goodreads.com/review/list/2977381-kirk-kittell?ref=nav_mybooks&shelf=to-read">to-read list</a>. I've been using the site since 2009 or so, and it's a fascinating journey to go back in and see what I added and when I added it&mdash;like touring past versions of myself.</p>

      ]]></content:encoded>
    </item>

    <item>
      <title>Escape velocity</title>
      <link>https://www.kirkkittell.com/story/2026-01-15.html#2026-01-15_01</link>
      <guid>https://www.kirkkittell.com/story/2026-01-15.html#2026-01-15_01</guid>
      <pubDate>Thu, 15 Jan 2026 20:00:00 CST</pubDate>
      <content:encoded><![CDATA[
      <blockquote><p>I looked for him to come dragging in after a few months. A lot of people leave Arkansas and most of them come back sooner or later. They can't quite achieve escape velocity. I expect it's much the same everywhere. </p></blockquote>
      <p>&mdash;Charles Portis, Chapter 19, <em>The Dog of the South</em> (1979)</p>
      <p>And now I'm done with this book. Almost sorry to see it go.</p>

      ]]></content:encoded>
    </item>

    <item>
      <title>If you can't walk, walk anyway</title>
      <link>https://www.kirkkittell.com/story/2026-01-14.html#2026-01-14_01</link>
      <guid>https://www.kirkkittell.com/story/2026-01-14.html#2026-01-14_01</guid>
      <pubDate>Wed, 14 Jan 2026 21:48:00 CST</pubDate>
      <content:encoded><![CDATA[
      <p>Sports are nice because the lessons are often simple.</p>
      <p>I was thinking of the middle of the 2013 Kodiak 50 miler up in Big Bear Lake, California. Not the whole thing, just a segment in the middle, from the bottom of Siberia Creek to the top and then over. It is certainly a top three toughest race segments that I ever dealt with. I don't remember how many miles that segment was. Call it seven or eight miles. What does it matter.</p>
      <p>There was supposed to be an aid station at the bottom. Maybe there was later, I don't know. I was the third runner to the bottom and there was no one there but a photographer. I wasn't out of water yet, but I would be soon. I didn't fill up at the aid station at the top. It's a running race, not a water carrying race. If you're not going to drink the water&mdash;and heading downhill in the shade of trees doesn't require much of it&mdash;don't carry it.</p>
      <p>As the great philsopher once said: womp womp.</p>
      <p>I typically run the uphills. It was my secret weapon. If you can't be fast, be tough. The trail footing was fairly loose rock, not the sort of thing that's worth pushing through, so I walked. Trudged, really. In the sun. Out of water. Scrubby trees. Tightening up. A brown bear cub ran across the trail in front of me. Freeze. No mom to be seen. No water. Switchbacks. Sun. Miles. Only a bag of gummy bears in the pocket of the hip belt I carried my water bottle in. Couldn't break them down, couldn't swallow them. Unscrewed my water bottle lid and tried to lick any remaining water out of the threads. Couple drops there. Caught up to another runner. (Walker. Trudger, really.) On and on and on and on until the aid station table hove into view.</p>
      <p>I prefer to get in and out of the aid stations. Don't stop unless you have. Smile and crack jokes, enjoy the company before you're off on the trail again with nothing but the monsters in your head for company. This aid station though... I remember drinking three Cokes. Two other runners (walkers) made it to the station. I headed off down the trail... then off on a side trail to take a moment to excrete blood. Back to the trail. A little more walking. Then the inflection point that I really remember.</p>
      <p>Endurance running, like any community of zealots, has a number of insipid cliches. They probably help sometimes. The one that stuck with me is: if you can't run, walk; if you can't walk, walk anyway. There were probably ten or fifteen miles left. Or eight or whatever. I created a game. Run one minute, walk one minute. Run two minutes, walk one minute. Run three minutes, walk one minute. At some point, I didn't need to do the walking anymore. Eventually I caught the three runners from the previous aid station at the next aid station. One of them finished up with me and we got <a href="https://ultrarunning.com/calendar/event/kodiak-100/race/9329/results">second and third</a>.</p>
      <p>It was a hard day. And a long time ago. Just stay upright, moving forward. All focus compressed into a single point. Not all, but some strength comes from within, and once you find what shelf it's hidden on, you know you can come back and find it later if you believe.</p>
      ]]></content:encoded>
    </item>

    <item>
      <title>The Captain's Newsletter, 2026-001</title>
      <link>https://www.kirkkittell.com/story/2026-01-11.html#2026-01-11_01</link>
      <guid>https://www.kirkkittell.com/story/2026-01-11.html#2026-01-11_01</guid>
      <pubDate>Sun, 11 Jan 2026 19:00:00 CST</pubDate>
      <content:encoded><![CDATA[
      <p>Emailed into the void: <a href="/newsletter/newsletter_2026-001.html">The Captain's Newsletter, 2026-001</a></p>
      ]]></content:encoded>
    </item>

    <item>
      <title>Graphs, Pandemic 2</title>
      <link>https://www.kirkkittell.com/story/2026-01-10.html#2026-01-10_01</link>
      <guid>https://www.kirkkittell.com/story/2026-01-10.html#2026-01-10_01</guid>
      <pubDate>Sat, 10 Jan 2026 22:00:00 CST</pubDate>
      <content:encoded><![CDATA[
<p>Previously: <a href="2026-01-03.html#2026-01-03_01">Graphs, Pandemic</a> (2026-01-03)</p>
      <p>I played around a little in Python and made a graph of the Pandemic game board, complete with all the nodes (cities) and edges (city-to-city paths).</p>
      <p>Code: <a href="https://github.com/kittell/kirkkittell.com/blob/main/story/attachments/2026-01-10/pandemic_graph.py">pandemic_graph.py</a>. It's not fancy. It just reads in a .csv file with a list of all cities (and their associated colors) and another .csv file that has the two cities that comprise an edge (path between cities). Then <a href="https://networkx.org/en/">NetworkX</a> builds the graph.</p>
      <p>So, I'll put that graph through its paces later to see what I can learn about the gameboard. Wildly unnecessary, I'm just curious. I feel like there's a way to make a game like this that can build a different sized graph (different set of cities, different connections, etc.) if the (theoretical) player wants to. Again, not necessary, but a toy to play with to see how things work. I don't think I'd ever take it that far, but it ought to be possible to simulate different game plays.</p>
      <p>Beyond analysis, pictures are worth at least a few words:</p>
      <img src="../story/attachments/2026-01-10/pandemic_graph.png" />
      <p>Back in the day, I used to be able to make a more interesting graph output using NetworkX&mdash;maybe using GraphViz somehow?</p>
      ]]></content:encoded>
    </item>

    <item>
      <title>Note hoarding</title>
      <link>https://www.kirkkittell.com/story/2026-01-09.html#2026-01-09_01</link>
      <guid>https://www.kirkkittell.com/story/2026-01-09.html#2026-01-09_01</guid>
      <pubDate>Fri, 09 Jan 2026 22:00:00 CST</pubDate>
      <content:encoded><![CDATA[

      <h2>Note hoarding</h2>
      <p>Taking off from <a href="2026-01-08.html#2026-01-09_01">yesterday</a>... Sometimes I wonder&mdash;useless, and worse I suppose, consciously useless&mdash;where to put things I collect, like lines that I pick up from books. Generally I grab them I hoard them in OneNote, a separate note from each book? Why? Compulsion, I'm sure. Some misguided urge to... ? To hold onto a good thought in case I need it later? To recharge some place in my brain that once found inspiration by stumbling onto the same inspiration again later? It's a mystery. There's no profit in it, for sure.</p>
      <p>Another minor reason, probably best classified under the header Justification, is that it would be interesting to share, for example, that quote so that someone else could enjoy it, or go and read the whole book. (The disservice of grabbing quotes is grabbing them without the connecting tissue, as if a sentence from a book could somehow live well without the rest of its body. Anyway, neither here nor there.) I used to be able to do that when I grabbed the quotes into Evernote, where I could share a public link. I don't think OneNote works like that. I'm not going to worry about it. I'll reinstate an old convention here: kirkkittell.com/ref. Useful? Who will ever know. A nice thing about running a straight HTML site is that I have no idea if anyone is ever here. Zero views? None the wiser. Anyway, I'll collect some notes from <em>The Dog of the South</em>, for instance, in <a href="http://www.kirkkittell.com/ref/reading/the-dog-of-the-south.html">kirkkittell.com/ref/reading/the-dog-of-the-south.html</a>, plus an index or navigation of sorts in /ref and /ref/reading. You're welcome.</p>

      ]]></content:encoded>
    </item>

    <item>
      <title>The Dog of the South</title>
      <link>https://www.kirkkittell.com/story/2026-01-08.html#2026-01-08_01</link>
      <guid>https://www.kirkkittell.com/story/2026-01-08.html#2026-01-08_01</guid>
      <pubDate>Thu, 08 Jan 2026 22:36:00 CST</pubDate>
      <content:encoded><![CDATA[
      <blockquote><p>I felt queasy. I took two of the orange pills. I can't say I was really sick, unless you count narcolepsy and mild xenophobia, but I was a little queasy.</p></blockquote>
      <p>Charles Portis. <em>The Dog of the South</em>. I can't believe (a) this book exists and (b) I've never heard of it before. Granted, I've been reading it for ages (surely the library will want it back soon) and I have read some Charles Portis before&mdash;only <em>True Grit</em>, which is famous enough to not need introduction.</p>
      <p>But: the dialogue. The patter. I can't imagine writing it. I recognize some of it&mdash;at least the way that people talk past and through each other. I'm from the middle of nowhere, not really from the South, but some of the same tendencies are there. We're not the same people, but we're not that far away. All of the ridiculous dialogue... it's alien, but familiar. I've got maybe 50 pages left to go, and I'm not even sure there's a plot, but I'm keenly plugged into the dialogue. Just give me some more Arkansan babbling, however it comes.</p>

      ]]></content:encoded>
    </item>
    
    <item>
      <title>Zhongwensday 2026-W02</title>
      <link>https://www.kirkkittell.com/story/2026-01-07.html#2026-01-07_01</link>
      <guid>https://www.kirkkittell.com/story/2026-01-07.html#2026-01-07_01</guid>
      <pubDate>Wed, 07 Jan 2026 07:08:00 CST</pubDate>
      <content:encoded><![CDATA[
      <p>Zhongwensday 2026-W02: <b><a href="/zhwotd/w/2026-W02.html">羊 (yáng)</a></b></p>
      <p>A little feature I've been meaning to include with Chinese Word of the Day for years. Finally using the opportunity of a new year to try it out.</p>

      ]]></content:encoded>
    </item>

    <item>
      <title>RSS</title>
      <link>https://www.kirkkittell.com/story/2026-01-06.html#2026-01-06_01</link>
      <guid>https://www.kirkkittell.com/story/2026-01-06.html#2026-01-06_01</guid>
      <pubDate>Tue, 06 Jan 2026 19:39:00 CST</pubDate>
      <content:encoded><![CDATA[
      <p>A few notes after reading: Dave Winer, "<a href="http://scripting.com/2025/12/14/142421.html?title=aReallySimpleSocialWeb">A Really Simple social web</a>", <em>Scripting News</em> (2025-12-14)</p>
      <p>Since I started writing again (occasionally, intermittently, &c.) last year, I've just been doing a straight HTML (+ CSS + JavaScript) website. The impetus for that was fairly simple: I had been paying a lot for web hosting over the years and I stopped doing that entirely. I think the folks at <a hr3ef="https://www.siteground.com">SiteGround</a> did a good job, but spending the money was a hard sell at home.</p>
      <p>Incidentally, I also like the attitude of running a site in plain HTML again&mdash;it's just like the 90s again. And I'm one of those people who yells at clouds about how the web used to be Good&mdash;well, if not Good like the quality of the web sites was good, but at least it was Nice. Maybe it was because everyone wasn't online yet, so the network effect of so many people yelling at each other hadn't been activated yet. I'm sure that's part of it. But also there was friction involved in creating and maintaining a site. If nothing else, some of the effort that could otherwise be spent on yelling had to be spent on doing what is now handled by Someone Else, some social media company or WordPress as a backend or whatever.</p>
      <p>So it's nice&mdash;Nice&mdash;to go back to a low quality site again. I'm not sure it will lead to high quality thoughts, but I'll be too busy opening and closing tags to care.</p>
      <p>Anyway, that wasn't the point. The point was: running a web site out of WordPress meant that I had a ready-to-go RSS feed. The software created it for me based on the post I entered into the backend form which was stored off in a database and some tables somewhere. It felt like something technically advanced&mdash;some kind of magic that I couldn't possibly understand.</p>
      <p>I looked into it. So. It's just an XML file with the text/code from the blog posts. Obviously. I'm not sure what I was expecting.</p>
      <p>So, here it is again: <a href="http://www.kirkkittell.com/rss.xml">kirkkittell.com/rss.xml</a>.</p>
      <p>One day I might automate some of this site&mdash;something that will allow easy changing of all the post templates, for example, or copying over HTML blog post articles into the RSS file. Or maybe not. I don't know. There's <em>something</em> satisfying about doing things the difficult, contrarian way, but maybe that's just my problems talking. In the meanwhile I'm going to copy and paste the text, just as Nature intended.</p>
      <p>Related, I guess: this many years later, it's still irritating that Google killed Google Reader... but I didn't realize it was all the way back in 2013 that it got axed. (David Pierce, "<a href="https://www.theverge.com/23778253/google-reader-death-2013-rss-social">Who killed Google Reader?</a>", <em>The Verge</em> (2023-06-30)). I use Feedly's <a href="https://feedly.com/news-reader">News Reader</a> now, which is probably the closest in spirit to Google Reader, but there will always be a Google Reader sized hole out there.</p>
      ]]></content:encoded>
    </item>

    <!-- Add more <item> blocks for each post -->

  </channel>
</rss>
